{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cfbde4",
   "metadata": {},
   "source": [
    "# Notion LLM Tutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeddc85",
   "metadata": {},
   "source": [
    "This notebook demonstrates a Notion-powered LLM tutor that answers technical questions using both general knowledge and reference material from a Notion page. It fetches, cleans, and incorporates Notion content to enhance explanations about Python, software engineering, data science, and LLMs. The workflow includes API setup, content extraction, prompt engineering, and model interaction for detailed, context-aware responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "075050a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import ollama\n",
    "import os\n",
    "from notion_client import Client as NotionClient\n",
    "from notion_exporter import NotionExporter\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "943fafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants and setup\n",
    "parent_dir = os.path.dirname(os.getcwd())  # Get the parent directory (GenAI-Discovery)\n",
    "env_path = os.path.join(parent_dir, '.env')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=env_path, override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "NOTION_API_KEY = os.getenv('NOTION_API_KEY')\n",
    "NOTION_PAGE_ID = os.getenv('NOTION_PAGE_ID')\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "\n",
    "# Initialize OpenAI client with API key\n",
    "CLIENT = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12d3312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n",
      "Notion API key looks good so far\n",
      "Notion Page ID looks good so far\n"
     ]
    }
   ],
   "source": [
    "# check OpenAI API key format\n",
    "if OPENAI_API_KEY and OPENAI_API_KEY.startswith('sk-proj-') and len(OPENAI_API_KEY)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key?\")\n",
    "    \n",
    "# check Notion API key format\n",
    "if NOTION_API_KEY and NOTION_API_KEY.startswith('ntn_') and len(NOTION_API_KEY)>10:\n",
    "    print(\"Notion API key looks good so far\")\n",
    "else:\n",
    "    print(\"Notion API key not found or invalid format\")\n",
    "\n",
    "# check Notion Page ID format (8-4-4-4-12 characters)\n",
    "if NOTION_PAGE_ID and \\\n",
    "    len(NOTION_PAGE_ID) == (32+4) and \\\n",
    "    all(len(part) == expected for part, expected in zip(NOTION_PAGE_ID.split('-'), [8, 4, 4, 4, 12])):\n",
    "    print(\"Notion Page ID looks good so far\")\n",
    "else:\n",
    "    print(\"Invalid Notion Page ID format. It should follow the pattern: 8-4-4-4-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b12d3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using NotionExporter instead as it handles block-to-markdown conversion\n",
    "# Initialize the client\n",
    "# notion = NotionClient(auth=NOTION_API_KEY)\n",
    "# Read a page\n",
    "# page = notion.pages.retrieve(page_id=NOTION_PAGE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b089ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need with NotionExporter as Jupyter is already a running event loop\n",
    "# Apply nest_asyncio to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Helper function to run async code in Jupyter\n",
    "def run_async(coro):\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        return loop.run_until_complete(coro)\n",
    "    except RuntimeError as e:\n",
    "        if \"There is no current event loop in thread\" in str(e):\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "            return loop.run_until_complete(coro)\n",
    "        raise\n",
    "    \n",
    "# Example of how to use run_async with an async function\n",
    "async def async_operation():\n",
    "    # Your async code here\n",
    "    pass\n",
    "\n",
    "# Run it using the helper\n",
    "result = run_async(async_operation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Notion page content\n",
    "exporter = NotionExporter(notion_token=NOTION_API_KEY)\n",
    "notion_content = exporter.export_pages(page_ids=[NOTION_PAGE_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be63d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string representation of the return content\n",
    "# notion_content[NOTION_PAGE_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ceb18bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_images_links_files(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove images, links and uploaded files (names and links) from an HTML/Markdown-ish string.\n",
    "    Handles:\n",
    "      - HTML <figure>...</figure> blocks (commonly wrap images)\n",
    "      - HTML <img ...> tags\n",
    "      - Markdown images: ![alt](url)\n",
    "      - HTML anchors: <a ...>...</a> (removes tag and inner text)\n",
    "      - Markdown links: [text](url)\n",
    "      - Standalone http(s):// URLs\n",
    "      - Bare filenames with common extensions (e.g. requirements.txt, report.pdf, diagnostics.ipynb)\n",
    "    Returns cleaned string with extra blank lines collapsed.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "\n",
    "    # Patterns to remove. Use DOTALL and IGNORECASE where needed.\n",
    "    patterns = [\n",
    "        # Remove entire figure blocks which often contain images/files\n",
    "        re.compile(r'(?is)<figure\\b.*?>.*?</figure>'),\n",
    "        # Remove img tags\n",
    "        re.compile(r'(?is)<img\\b[^>]*>'),\n",
    "        # Remove markdown images ![alt](url)\n",
    "        re.compile(r'!\\[.*?\\]\\(.*?\\)'),\n",
    "        # Remove HTML anchors and their content (link text or file name)\n",
    "        re.compile(r'(?is)<a\\b[^>]*>.*?</a>'),\n",
    "        # Remove markdown links [text](url)\n",
    "        re.compile(r'\\[.*?\\]\\(.*?\\)'),\n",
    "        # Remove standalone URLs (http/https)\n",
    "        re.compile(r'https?://\\S+'),\n",
    "        # Remove bare filenames with common extensions (case-insensitive)\n",
    "        re.compile(r'(?i)\\b[\\w\\-\\.() ]+\\.(?:pdf|txt|ipynb|py|yml|yaml|md|docx|pptx|csv|xlsx|png|jpe?g|gif|zip|tar|gz)\\b'),\n",
    "    ]\n",
    "\n",
    "    cleaned = text\n",
    "    for pat in patterns:\n",
    "        cleaned = pat.sub('', cleaned)\n",
    "\n",
    "    # Remove common leftover HTML attributes or sequences like src=\"...\" or href=\"...\" if any remain (optional)\n",
    "    cleaned = re.sub(r'(?i)\\b(src|href)=[\"\\'][^\"\\']*[\"\\']', '', cleaned)\n",
    "\n",
    "    # Remove leftover sequences of punctuation that might remain after filename removal (e.g., ' ,', ' .')\n",
    "    cleaned = re.sub(r'[\\s]*[,;:\\-][\\s]*', ' ', cleaned)\n",
    "\n",
    "    # Collapse multiple blank lines into two and trim\n",
    "    cleaned = re.sub(r'\\n\\s*\\n+', '\\n\\n', cleaned).strip()\n",
    "\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9ed8a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove attached files, images, links from Notion page content\n",
    "notion_content_clean = remove_images_links_files(notion_content[NOTION_PAGE_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9ed8a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original content\n",
    "# display(Markdown(notion_content[NOTION_PAGE_ID]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "52e31ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned content\n",
    "# display(Markdown(notion_content_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52e31ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example question:\n",
    "# What was the first built project in this course?\n",
    "question = input(\"Please enter your question:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "186669c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt length: 52560 characters\n",
      "Contains Notion content: Yes\n"
     ]
    }
   ],
   "source": [
    "# Create enhanced system prompt with Notion content\n",
    "base_system_prompt = \"\"\"You are a helpful technical tutor who answers questions about python code, software engineering, data science and LLMs.\n",
    "\n",
    "You have access to additional reference material that may be relevant to the user's questions. Use this information to provide more comprehensive and accurate answers when applicable.\n",
    "\n",
    "REFERENCE MATERIAL:\n",
    "\"\"\"\n",
    "\n",
    "# Combine base prompt with Notion content\n",
    "if notion_content_clean:\n",
    "    system_prompt = base_system_prompt + f\"\\n{notion_content_clean}\\n\\n\" + \"\"\"\n",
    "INSTRUCTIONS:\n",
    "- Use the reference material above when it's relevant to the user's question\n",
    "- Always prioritize accuracy and clarity in your explanations\n",
    "- If the reference material contains relevant information, mention that you're drawing from additional resources\n",
    "- If the question is outside the scope of the reference material, answer based on your general knowledge\n",
    "\"\"\"\n",
    "else:\n",
    "    system_prompt = \"You are a helpful technical tutor who answers questions about python code, software engineering, data science and LLMs\"\n",
    "\n",
    "user_prompt = \"Please give a detailed explanation to the following question: \" + question\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "# Show system prompt length for debugging\n",
    "print(f\"System prompt length: {len(system_prompt)} characters\")\n",
    "print(f\"Contains Notion content: {'Yes' if notion_content else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "228ee37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/30/2025 03:48:24 PM HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The first project in the course is the **\"Instant Gratification Project: Creating an AI Powered Web Page Summarizer.\"** Here’s a breakdown of what this project involves:\n",
       "\n",
       "### Overview of the Project\n",
       "The goal of the project is to build a web page summarization tool using a large language model (LLM). It allows users to input a URL and receive a concise summary of the contents on that webpage. This showcases how LLMs can be applied to real-world tasks like summarization.\n",
       "\n",
       "### Key Components of the Project\n",
       "\n",
       "1. **Environment Setup:**\n",
       "   - Prior to starting the project, participants are instructed to set up their development environment, which includes tools like Jupyter Lab, Python, and the necessary libraries such as Beautiful Soup for web scraping.\n",
       "\n",
       "2. **Retrieving Web Content:**\n",
       "   - The project involves creating a class `Website`, which is responsible for fetching the content of a specified URL. It uses the `requests` library to get the HTML content and `BeautifulSoup` to parse that content. The class extracts the webpage's title and main text while filtering out irrelevant elements such as scripts and styles.\n",
       "\n",
       "3. **Generating Summaries with LLM:**\n",
       "   - The project utilizes an LLM (like OpenAI’s GPT models or Ollama's Llama model) to process the extracted content. \n",
       "   - Participants define **system and user prompts** to guide the LLM in generating a summary. The system prompt sets the context for the task, while the user prompt provides the content that needs summarization.\n",
       "\n",
       "4. **API Integration:**\n",
       "   - The project includes making API calls to the OpenAI service or to local instances of models like Llama using Ollama. This entails setting up the necessary API keys and routes for making requests to the LLM.\n",
       "\n",
       "5. **Combining Components:**\n",
       "   - Finally, the various components (web scraping, LLM integration, and output formatting) are combined into a cohesive function to create the summarizer. The results are formatted and displayed in a user-friendly Markdown format.\n",
       "\n",
       "### Example Code Snippets\n",
       "Here is a simplified version of what parts of the implementation may look like:\n",
       "\n",
       "python\n",
       "import requests\n",
       "from bs4 import BeautifulSoup\n",
       "\n",
       "class Website:\n",
       "    def __init__(self, url):\n",
       "        self.url = url\n",
       "        response = requests.get(url)\n",
       "        soup = BeautifulSoup(response.content, 'html.parser')\n",
       "        self.title = soup.title.string if soup.title else \"No title found\"\n",
       "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
       "\n",
       "# Function to summarize the content using LLM\n",
       "def summarize(url):\n",
       "    website = Website(url)\n",
       "    # Here you would call the LLM API with the website.text to get a summary\n",
       "    # For example:\n",
       "    response = openai.chat.completions.create(\n",
       "        model='your-llm-model',\n",
       "        messages=[\n",
       "            {\"role\": \"system\", \"content\": \"Summarize the content of the following text.\"},\n",
       "            {\"role\": \"user\", \"content\": website.text}\n",
       "        ]\n",
       "    )\n",
       "    return response.choices[0].message.content\n",
       "\n",
       "# Example usage\n",
       "print(summarize(\"http://example.com\"))\n",
       "\n",
       "\n",
       "### Learning Outcomes\n",
       "- Participants gain practical experience in web scraping, API integration, and working with LLMs.\n",
       "- The project emphasizes understanding how to construct effective prompts and manage the flow of data from input (web content) to output (summarized text).\n",
       "\n",
       "This formative project sets the stage for the entire course by illustrating critical concepts and skills relevant to working with LLMs and applying them to solve real-world problems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "stream = CLIENT.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af07fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "response = ollama.chat(model=MODEL_LLAMA, messages=messages)\n",
    "reply = response['message']['content']\n",
    "display(Markdown(reply))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
